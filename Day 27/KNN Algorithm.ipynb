{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "data = pd.read_csv('train.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data['Sex'] = le.fit_transform(data['Sex'])\n",
    "data['Embarked'] = le.fit_transform(data['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0         0       3    1  22.0      1      0   7.2500         2\n",
       "1         1       1    0  38.0      1      0  71.2833         0\n",
       "2         1       3    0  26.0      0      0   7.9250         2\n",
       "3         1       1    0  35.0      1      0  53.1000         2\n",
       "4         0       3    1  35.0      0      0   8.0500         2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "y=data['Pclass']\n",
    "X=data.drop(['Pclass'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KnnVal(kval):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=kval)\n",
    "    acc_score = knn.fit(X_train,y_train).score(X_test,y_test)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    confusion_matrix(y_test,y_pred)\n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.8913857677902621, 2: 0.8651685393258427, 3: 0.8651685393258427, 4: 0.8239700374531835, 5: 0.8314606741573034, 6: 0.846441947565543, 7: 0.8426966292134831, 8: 0.850187265917603, 9: 0.846441947565543, 10: 0.8352059925093633, 11: 0.8202247191011236, 12: 0.8277153558052435, 13: 0.8277153558052435, 14: 0.8202247191011236, 15: 0.8127340823970037, 16: 0.8164794007490637, 17: 0.8164794007490637, 18: 0.8164794007490637, 19: 0.8202247191011236, 20: 0.8202247191011236, 21: 0.8127340823970037, 22: 0.797752808988764, 23: 0.8014981273408239, 24: 0.7940074906367042, 25: 0.797752808988764, 26: 0.7865168539325843, 27: 0.797752808988764, 28: 0.7827715355805244, 29: 0.7790262172284644, 30: 0.7790262172284644, 31: 0.7865168539325843, 32: 0.7827715355805244, 33: 0.7902621722846442, 34: 0.7865168539325843, 35: 0.7790262172284644, 36: 0.7827715355805244, 37: 0.7865168539325843, 38: 0.7902621722846442, 39: 0.7752808988764045, 40: 0.7902621722846442, 41: 0.7827715355805244, 42: 0.7865168539325843, 43: 0.7827715355805244, 44: 0.7865168539325843, 45: 0.7827715355805244, 46: 0.7865168539325843, 47: 0.7752808988764045, 48: 0.7752808988764045, 49: 0.7752808988764045, 50: 0.7715355805243446, 51: 0.7715355805243446, 52: 0.7715355805243446, 53: 0.7677902621722846, 54: 0.7677902621722846, 55: 0.7715355805243446, 56: 0.7752808988764045, 57: 0.7752808988764045, 58: 0.7677902621722846, 59: 0.7602996254681648, 60: 0.7640449438202247, 61: 0.7602996254681648, 62: 0.7602996254681648, 63: 0.7565543071161048, 64: 0.7565543071161048, 65: 0.7602996254681648, 66: 0.7565543071161048, 67: 0.7602996254681648, 68: 0.7602996254681648, 69: 0.7640449438202247, 70: 0.7640449438202247, 71: 0.7640449438202247, 72: 0.7565543071161048, 73: 0.7640449438202247, 74: 0.7677902621722846, 75: 0.7640449438202247, 76: 0.7677902621722846, 77: 0.7715355805243446, 78: 0.7640449438202247, 79: 0.7565543071161048, 80: 0.7565543071161048, 81: 0.7602996254681648, 82: 0.7602996254681648, 83: 0.7528089887640449, 84: 0.7528089887640449, 85: 0.7490636704119851, 86: 0.7490636704119851, 87: 0.7490636704119851, 88: 0.7453183520599251, 89: 0.7490636704119851, 90: 0.7565543071161048, 91: 0.7565543071161048, 92: 0.7565543071161048, 93: 0.7528089887640449, 94: 0.7528089887640449, 95: 0.7528089887640449, 96: 0.7565543071161048, 97: 0.7453183520599251, 98: 0.7565543071161048, 99: 0.7378277153558053, 100: 0.7378277153558053, 101: 0.7303370786516854, 102: 0.7303370786516854, 103: 0.7340823970037453, 104: 0.7340823970037453, 105: 0.7378277153558053, 106: 0.7415730337078652, 107: 0.7415730337078652, 108: 0.7453183520599251, 109: 0.7490636704119851, 110: 0.7528089887640449, 111: 0.7490636704119851, 112: 0.7453183520599251, 113: 0.7490636704119851, 114: 0.7490636704119851, 115: 0.7490636704119851, 116: 0.7490636704119851, 117: 0.7528089887640449, 118: 0.7490636704119851, 119: 0.7490636704119851, 120: 0.7453183520599251, 121: 0.7453183520599251, 122: 0.7453183520599251, 123: 0.7415730337078652, 124: 0.7453183520599251, 125: 0.7453183520599251, 126: 0.7490636704119851, 127: 0.7490636704119851, 128: 0.7528089887640449, 129: 0.7528089887640449, 130: 0.7602996254681648, 131: 0.7602996254681648, 132: 0.7602996254681648, 133: 0.7602996254681648, 134: 0.7565543071161048, 135: 0.7602996254681648, 136: 0.7602996254681648, 137: 0.7602996254681648, 138: 0.7602996254681648, 139: 0.7602996254681648, 140: 0.7602996254681648, 141: 0.7602996254681648, 142: 0.7565543071161048, 143: 0.7565543071161048, 144: 0.7565543071161048, 145: 0.7565543071161048, 146: 0.7565543071161048, 147: 0.7640449438202247, 148: 0.7677902621722846, 149: 0.7677902621722846, 150: 0.7677902621722846, 151: 0.7677902621722846, 152: 0.7640449438202247, 153: 0.7640449438202247, 154: 0.7640449438202247, 155: 0.7640449438202247, 156: 0.7602996254681648, 157: 0.7565543071161048, 158: 0.7565543071161048, 159: 0.7565543071161048, 160: 0.7565543071161048, 161: 0.7528089887640449, 162: 0.7528089887640449, 163: 0.7528089887640449, 164: 0.7528089887640449, 165: 0.7528089887640449, 166: 0.7528089887640449, 167: 0.7528089887640449, 168: 0.7528089887640449, 169: 0.7528089887640449, 170: 0.7528089887640449, 171: 0.7528089887640449, 172: 0.7528089887640449, 173: 0.7565543071161048, 174: 0.7490636704119851, 175: 0.7565543071161048, 176: 0.7565543071161048, 177: 0.7565543071161048, 178: 0.7565543071161048, 179: 0.7565543071161048, 180: 0.7490636704119851, 181: 0.7565543071161048, 182: 0.7565543071161048, 183: 0.7565543071161048, 184: 0.7528089887640449, 185: 0.7528089887640449, 186: 0.7490636704119851, 187: 0.7490636704119851, 188: 0.7490636704119851, 189: 0.7453183520599251, 190: 0.7415730337078652, 191: 0.7415730337078652, 192: 0.7415730337078652, 193: 0.7415730337078652, 194: 0.7303370786516854, 195: 0.7228464419475655, 196: 0.7228464419475655, 197: 0.7228464419475655, 198: 0.7228464419475655, 199: 0.7191011235955056, 200: 0.7191011235955056, 201: 0.7228464419475655, 202: 0.7228464419475655, 203: 0.7228464419475655, 204: 0.7228464419475655, 205: 0.7228464419475655, 206: 0.7228464419475655, 207: 0.7228464419475655, 208: 0.7228464419475655, 209: 0.7228464419475655, 210: 0.7228464419475655, 211: 0.7228464419475655, 212: 0.7228464419475655, 213: 0.7228464419475655, 214: 0.7228464419475655, 215: 0.7228464419475655, 216: 0.7228464419475655, 217: 0.7228464419475655, 218: 0.7228464419475655, 219: 0.7228464419475655, 220: 0.7228464419475655, 221: 0.7228464419475655, 222: 0.7228464419475655, 223: 0.7228464419475655, 224: 0.7228464419475655, 225: 0.7228464419475655, 226: 0.7228464419475655, 227: 0.7228464419475655, 228: 0.7228464419475655, 229: 0.7228464419475655, 230: 0.7228464419475655, 231: 0.7228464419475655, 232: 0.7228464419475655, 233: 0.7228464419475655, 234: 0.7228464419475655, 235: 0.7228464419475655, 236: 0.7228464419475655, 237: 0.7228464419475655, 238: 0.7228464419475655, 239: 0.7228464419475655, 240: 0.7228464419475655, 241: 0.7228464419475655, 242: 0.7228464419475655, 243: 0.7228464419475655, 244: 0.7191011235955056, 245: 0.7191011235955056, 246: 0.7191011235955056, 247: 0.7191011235955056, 248: 0.7191011235955056, 249: 0.7191011235955056, 250: 0.7191011235955056, 251: 0.7191011235955056, 252: 0.7191011235955056, 253: 0.7191011235955056, 254: 0.7191011235955056, 255: 0.7191011235955056, 256: 0.7191011235955056, 257: 0.7191011235955056, 258: 0.7191011235955056, 259: 0.7191011235955056, 260: 0.7191011235955056, 261: 0.7191011235955056, 262: 0.7191011235955056, 263: 0.7191011235955056, 264: 0.7191011235955056, 265: 0.7191011235955056, 266: 0.7153558052434457}\n"
     ]
    }
   ],
   "source": [
    "scoreDict = {}\n",
    "for i in range(1,len(X_test)):\n",
    "    accScore = KnnVal(i)\n",
    "    scoreDict[i] = accScore\n",
    "print(scoreDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation\n",
    "\n",
    "k=1 gives the maximum accuracy score of 89%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
